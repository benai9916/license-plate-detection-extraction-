{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "license_plate_detection_ORC (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benai9916/license-plate-detection-extraction-/blob/main/license_plate_detection_and_ORC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1lejWNQn5Tn"
      },
      "source": [
        "# Number plate detection\n",
        "\n",
        "## Installation\n",
        "Installing the Tensorflow Object Detection API became a lot easier with the relase of Tensorflow 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuVzhglRjHQl",
        "outputId": "422987a5-a597-4cc9-d9cd-ac9692dcf896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Sep 27 07:44:12 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTUTPukLPywq"
      },
      "source": [
        "# !pip install -U --pre tensorflow==\"2.2.0\"\n",
        "\n",
        "!pip install tensorflow-gpu\n",
        "\n",
        "# library to load file from google drive\n",
        "!pip install gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjdMBvjWsQSl",
        "outputId": "fbf71713-d003-4722-ab16-0840e1a7da67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "    \n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2198, done.\u001b[K\n",
            "remote: Counting objects: 100% (2198/2198), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1900/1900), done.\u001b[K\n",
            "remote: Total 2198 (delta 527), reused 959 (delta 272), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2198/2198), 30.43 MiB | 25.60 MiB/s, done.\n",
            "Resolving deltas: 100% (527/527), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTgNsCndsQXZ"
      },
      "source": [
        "# Install the Object Detection API\n",
        "\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCNfLhAftaB2"
      },
      "source": [
        "#run model builder test\n",
        "\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgWbgsuMywkX"
      },
      "source": [
        "# Prepare data\n",
        "After collecting the images we need to \n",
        "- label image, for this I am using [LabelImg](https://github.com/tzutalin/labelImg) - an free, open source graphical image annotation tool.\n",
        "- create pbtxt file which will include no of class labels\n",
        "- convert xml file into single csv\n",
        "- create TFrecord file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_JqbXxlDqc6",
        "outputId": "bd71581e-0d2b-422e-bc5e-ec8bed9646bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# download file to generate TFrecord\n",
        "\n",
        "!wget https://gist.githubusercontent.com/benai9916/fe9b432640ce3153c5ed93b471d95896/raw/27dae42e83e48d56767d6888d8954686232135ba/generate_tfrecord.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-27 07:46:23--  https://gist.githubusercontent.com/benai9916/fe9b432640ce3153c5ed93b471d95896/raw/27dae42e83e48d56767d6888d8954686232135ba/generate_tfrecord.py\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3216 (3.1K) [text/plain]\n",
            "Saving to: ‘generate_tfrecord.py’\n",
            "\n",
            "\rgenerate_tfrecord.p   0%[                    ]       0  --.-KB/s               \rgenerate_tfrecord.p 100%[===================>]   3.14K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-09-27 07:46:23 (71.3 MB/s) - ‘generate_tfrecord.py’ saved [3216/3216]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8wr3Mp5D1r5",
        "outputId": "1693c71c-4d77-41ad-ee3d-3b4e7b57083d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# load file to convert xml to csv\n",
        "\n",
        "!wget https://gist.githubusercontent.com/benai9916/8d6f4f3ce35e5063ae0487ce2a88d4db/raw/d666a4684102ca878da8c984480920885a17321d/xml_to_csv.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-27 07:46:23--  https://gist.githubusercontent.com/benai9916/8d6f4f3ce35e5063ae0487ce2a88d4db/raw/d666a4684102ca878da8c984480920885a17321d/xml_to_csv.py\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1198 (1.2K) [text/plain]\n",
            "Saving to: ‘xml_to_csv.py’\n",
            "\n",
            "\rxml_to_csv.py         0%[                    ]       0  --.-KB/s               \rxml_to_csv.py       100%[===================>]   1.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-09-27 07:46:23 (90.6 MB/s) - ‘xml_to_csv.py’ saved [1198/1198]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBA9sWPN4J5W",
        "outputId": "35ec87c9-05bf-4330-f828-ef4c49e03917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# load dataset, file to generate TRrecord and xml_to_csv\n",
        "\n",
        "if os.path.exists('images.zip'):\n",
        "  print('File already exists')\n",
        "else:\n",
        "  !gdown --id 1kqqaf7ADtR0Dhn1OzE4yfWKH3UB4MVA7 --output images.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kqqaf7ADtR0Dhn1OzE4yfWKH3UB4MVA7\n",
            "To: /content/images.zip\n",
            "21.8MB [00:00, 59.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLaajrx44J-z"
      },
      "source": [
        "# unzip\n",
        "\n",
        "!unzip images.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZq2rEVPip6d",
        "outputId": "aaa6a96e-7b9c-4ab6-e880-7e87d1e17f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYnTThLPt-T7"
      },
      "source": [
        "# Convert image to RGB\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "for file in os.listdir('images/test'):\n",
        "  if file.split('.')[1] == 'jpg':\n",
        "    img = Image.open('images/test/'+ file)\n",
        "    if img.mode != 'RGB':\n",
        "      img.convert('RGB')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIt5cFBto6-U"
      },
      "source": [
        "for file in os.listdir('images/train'):\n",
        "  if file.split('.')[1] == 'jpg':\n",
        "    img = Image.open('images/train/'+ file)\n",
        "    if img.mode != 'RGB':\n",
        "      img.convert('RGB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPSzzUreIHPA"
      },
      "source": [
        "# mak directory for csv\n",
        "\n",
        "os.mkdir('labels')\n",
        "\n",
        "\n",
        "# generate csv\n",
        "\n",
        "!python xml_to_csv.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsAFRWx34KB-",
        "outputId": "645444fa-b737-45c6-82b2-2a932efa3226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# make dir for tfrecord\n",
        "\n",
        "os.mkdir('tfrecord')\n",
        "\n",
        "\n",
        "# convert to csv file to TFrecord\n",
        "\n",
        "!python generate_tfrecord.py --csv_input=labels/train_labels.csv --image_dir=images/train --output_path=tfrecord/train.record\n",
        "!python generate_tfrecord.py --csv_input=labels/test_labels.csv --image_dir=images/test --output_path=tfrecord/test.record"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-27 07:46:28.269043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Successfully created the TFRecords: /content/tfrecord/train.record\n",
            "2020-09-27 07:46:30.675173: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Successfully created the TFRecords: /content/tfrecord/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VuswLW54KFp"
      },
      "source": [
        "# specify paths\n",
        "\n",
        "train_record_path = 'tfrecord/train.record'\n",
        "test_record_path = 'tfrecord/test.record'\n",
        "labelmap_path = 'label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7sOg6lBND8X"
      },
      "source": [
        "## Configuring training\n",
        "\n",
        "There are many pre-trained object detection models available in the [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). In order to train them using our custom data set, the models need to be restored in Tensorflow using their checkpoints (.ckpt files), which are records of previous model states.\n",
        "\n",
        "I am going to use `ssd_mobilenet_v2_coco`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKxc4bL-Mtrw",
        "outputId": "1a76ed37-30f6-46d8-90b8-594f98b1cae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# load pre trained\n",
        "\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
        "\n",
        "!tar -xf efficientdet_d0_coco17_tpu-32.tar.gz\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-27 07:46:32--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.195.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.195.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30736482 (29M) [application/x-tar]\n",
            "Saving to: ‘efficientdet_d0_coco17_tpu-32.tar.gz’\n",
            "\n",
            "efficientdet_d0_coc 100%[===================>]  29.31M   137MB/s    in 0.2s    \n",
            "\n",
            "2020-09-27 07:46:32 (137 MB/s) - ‘efficientdet_d0_coco17_tpu-32.tar.gz’ saved [30736482/30736482]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvKxz6HzpTyl"
      },
      "source": [
        "fine_tune_checkpoint = 'efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTbjOa_MMtvb",
        "outputId": "db8c8a00-9d27-4dac-a4de-676a858bd0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# download the configuration file\n",
        "\n",
        "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n",
        "\n",
        "base_config_path = 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-27 07:46:33--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4630 (4.5K) [text/plain]\n",
            "Saving to: ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config’\n",
            "\n",
            "\r          ssd_effic   0%[                    ]       0  --.-KB/s               \rssd_efficientdet_d0 100%[===================>]   4.52K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-09-27 07:46:33 (58.3 MB/s) - ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config’ saved [4630/4630]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BS8QsmQ4J82"
      },
      "source": [
        "batch_size = 16\n",
        "num_steps = 8000\n",
        "num_eval_steps = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX38PAr7Ub3t"
      },
      "source": [
        "In `config` file we need to change:\n",
        "- Since we’re only trying to license plate, change num_classes to 1\n",
        "- `fine_tune_checkpoint` tells the model which checkpoint file to use. Set this to `checkpoints/model.ckpt`\n",
        "- The model also needs to know where the TFRecord files and label maps are for both training and validation sets. Since our `train.record` and test.record are saved in tf_record folder, our config should reflect that:\n",
        "- change the `batch_size`, `num_step`, `num_eval_steps`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3J5zQZvpEMz"
      },
      "source": [
        "import re\n",
        "\n",
        "with open(base_config_path) as f:\n",
        "    config = f.read()\n",
        "\n",
        "with open('model.config', 'w') as f:\n",
        "  \n",
        "  # Set labelmap path\n",
        "  config = re.sub('label_map_path: \".*?\"', \n",
        "             'label_map_path: \"{}\"'.format(labelmap_path), config)\n",
        "  \n",
        "  # Set fine_tune_checkpoint path\n",
        "  config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n",
        "  \n",
        "  # Set train tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(train_record_path), config)\n",
        "  \n",
        "  # Set test tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(test_record_path), config)\n",
        "  \n",
        "  # Set number of classes.\n",
        "  config = re.sub('num_classes: [0-9]+',\n",
        "                  'num_classes: {}'.format(1), config)\n",
        "  \n",
        "  # Set batch size\n",
        "  config = re.sub('batch_size: [0-9]+',\n",
        "                  'batch_size: {}'.format(batch_size), config)\n",
        "  \n",
        "  # Set training steps\n",
        "  config = re.sub('num_steps: [0-9]+',\n",
        "                  'num_steps: {}'.format(num_steps), config)\n",
        "  \n",
        "  # Set fine-tune checkpoint type to detection\n",
        "  config = re.sub('fine_tune_checkpoint_type: \"classification\"', \n",
        "             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n",
        "  \n",
        "  f.write(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikSHcPaVSf1E"
      },
      "source": [
        "%cat model.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxSI9QhuSf41"
      },
      "source": [
        "model_dir = 'training/'\n",
        "pipeline_config_path = 'model.config'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y99Q_7G6gRDo"
      },
      "source": [
        "## Train detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6FQdLa5Wt1Y"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_config_path} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6SMTzWJX3vW"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8xbEXnc0gat"
      },
      "source": [
        "The below code cell adds a line to the tf_utils.py file. This is a temporary fix to a [exporting issue](https://github.com/tensorflow/models/issues/8841) occuring when using the OD API with Tensorflow 2. This code will be removed as soon as the OD Team puts out a fix.\n",
        "\n",
        "All credit goes to Github user [Jacobsolawetz](https://github.com/Jacobsolawetz), who provided this [temporary fix](https://github.com/tensorflow/models/issues/8841#issuecomment-657647648)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7FvCzAxNZur"
      },
      "source": [
        "with open('/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py') as f:\n",
        "    tf_utils = f.read()\n",
        "\n",
        "with open('/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py', 'w') as f:\n",
        "  # Set labelmap path\n",
        "  throw_statement = \"raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))\"\n",
        "  tf_utils = tf_utils.replace(throw_statement, \"if not isinstance(x, str):\" + throw_statement)\n",
        "  f.write(tf_utils)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt97sjZINZ26"
      },
      "source": [
        "# generate an inference graph\n",
        "\n",
        "output_directory = 'inference_graph'\n",
        "\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir {model_dir} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_config_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "draDMHa-NZyp"
      },
      "source": [
        "# download the graph\n",
        "\n",
        "from google.colab import files\n",
        "files.download(f'/content/{output_directory}/saved_model/saved_model.pb') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPNj7Ueg2Vaz"
      },
      "source": [
        "# Test model on test images\n",
        "\n",
        "based on [Object Detection API Demo](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb) and [Inference from saved model tf2 colab](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/inference_from_saved_model_tf2_colab.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTPPxu3O2Iwe"
      },
      "source": [
        "# Import libraries\n",
        "\n",
        "import io\n",
        "import os\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import six\n",
        "import time\n",
        "import glob\n",
        "from IPython.display import display\n",
        "\n",
        "from six import BytesIO\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyvJCtGs2I0L"
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: a file path (this can be local or on colossus)\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "\n",
        "  return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_aKl77I2ots"
      },
      "source": [
        "# indexing the category\n",
        "# labelmap_path = 'label_map.pbtxt'\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az9ah3QB2oxJ"
      },
      "source": [
        "# load model\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.saved_model.load(f'/content/{output_directory}/saved_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8WMsVIRJ46P"
      },
      "source": [
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  \n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  model_fn = model.signatures['serving_default']\n",
        "  output_dict = model_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "   \n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])      \n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "\n",
        "    \n",
        "  return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4sCJCpHKSms"
      },
      "source": [
        "# for image_path in glob.glob('microcontroller-detection/test/*.jpg'):\n",
        "\n",
        "image_np = load_image_into_numpy_array('images/test/3.jpg')\n",
        "output_dict = run_inference_for_single_image(model, image_np)\n",
        "vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "    image_np,\n",
        "    output_dict['detection_boxes'],\n",
        "    output_dict['detection_classes'],\n",
        "    output_dict['detection_scores'],\n",
        "    category_index,\n",
        "    instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "    use_normalized_coordinates=True,\n",
        "    line_thickness=4)\n",
        "\n",
        "display(Image.fromarray(image_np))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2qA3vvKbxYX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvTBV_lndVTn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
